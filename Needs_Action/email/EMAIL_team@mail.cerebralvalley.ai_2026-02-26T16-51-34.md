---
has_attachments: false
labels:
- UNREAD
- IMPORTANT
- CATEGORY_UPDATES
- INBOX
message_id: 19c53c37b2f33727
priority: high
received: '2026-02-12T21:30:44+00:00'
requires_approval: false
sender_email: team@mail.cerebralvalley.ai
source: Cerebral Valley <team@mail.cerebralvalley.ai>
status: pending
subject: FriendliAI - The Inference Engine Behind vLLM
thread_id: 19c53c37b2f33727
type: email
---

## Email Content

View image: (https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/440573d3-f114-4c50-a65f-14d8457ad674/DD2.png?t=1747020074)
Caption: 

## CV Deep Dive

**Today, we’re talking with **[Byung-Gon Chun (Gon)](https://www.linkedin.com/in/byung-gon-chun/)**, Founder and CEO of **[FriendliAI](https://friendli.ai)**.**

**If you’ve used vLLM, you’ve used technology that traces back to Gon’s research.** His lab at Seoul National University published the ORCA paper, which introduced Continuous Batching, a technique that fundamentally changed how LLM inference engines handle concurrent requests. ORCA directly inspired vLLM and has since become an industry standard across virtually every major serving framework. The team behind one of the most influential advances in modern inference infrastructure is now building the platform to make it all accessible.

**FriendliAI is a world-class inference platform that helps teams deploy and scale large open-source and custom AI models efficiently, reliably, and at significantly lower cost.** Built on a proprietary inference stack optimized across batching, quantization, scheduling, caching, and GPU kernels, Friendli positions itself as a premier alternative to closed model providers like OpenAI and Anthropic, offering comparable performance and convenience for the world’s best open-source models without the proprietary markup. The platform supports serverless APIs, dedicated endpoints, and container-based deployments including fully on-prem setups, giving teams the flexibility to choose the right deployment without being locked into a single approach.

**Friendli was founded on a conviction that training was getting all the attention, but inference was quietly becoming the real bottleneck** where cost, latency, and reliability challenges compound as AI moves from research demos into production systems serving millions of users. Today, the platform serves AI-native st

## Metadata

- **From:** Cerebral Valley <team@mail.cerebralvalley.ai>
- **To:** "shazil.akn@gmail.com" <shazil.akn@gmail.com>
- **Date:** 2026-02-12T21:30:44+00:00
- **Attachments:** None

## Suggested Actions

- [ ] Reply to sender
- [ ] Forward to relevant party
- [ ] Flag for follow-up
- [ ] Archive after processing
